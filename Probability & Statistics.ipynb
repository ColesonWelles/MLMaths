{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c711805e-7056-444c-aff7-38d41533f364",
   "metadata": {},
   "source": [
    "# Probability and Statistics\n",
    "\n",
    "Much of machine learning is also about uncertainty. In supervised learning, we hope to predict something unknown given something known (targets vs features). Models that are trained in this way attempt to predict the mostly likely value of a given target. Alternatively, these models may attempt to predict the value with the smallest expected distance from the target while also trying to *quantify our uncertainty*. \n",
    "\n",
    "With models under unsupervised learning, we especially care about uncertainty. We do so in order to determine whether a set of measurements are anomalous or to know how likely a set of values are in a given population. \n",
    "\n",
    "With reinforcement learning, the dream is to develop agents that can act intelligently under a variety of conditions and within a variety of environments. This presupposes a need to be able to reason about how an environment may be expected to change and what rewards a model might expect to encounter as result of a various possible actions it could take. \n",
    "\n",
    "\n",
    "**Probability** is the field of mathematics that covers all of these concerns vis a vis reasoning under uncertainity. The use of probabilities to describe the frequencies of repeatable events is pretty standard practice. Broadly speaking, **frequentists** adhere to an interpretation of probability that only applies to repeatable events. By contrast, **Bayesians** use the language of probability more broadly to formalize reasoning under uncertainty.\n",
    "\n",
    "Bayesian probability is characterized by two unique features:\n",
    "\n",
    "1) assigning degrees of belief to non-repreatable events e.g., \"what is the *probability* that a dam will collapse?\"\n",
    "\n",
    "2) subjectivity. While Bayesian probability provides unambiguous rules for how one should update their beliefs in light of new evidence, it allows for different individuals to start off with different *prior* beliefs.\n",
    "\n",
    "**Statistics** helps us to reason backwards, starting off with collection and organization of data and backing out to what inferences we might draw about the process that generated the data. Whenever we analye a dataset, hunting for patterns that we hope might characterize a broader population, we are employing statistical thinking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5651b4-33c3-44ab-9b14-488bf190e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "from torch.distributions.multinomial import Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c50bc-25d7-4892-b4fc-4cfba8930d30",
   "metadata": {},
   "source": [
    "## Starting off simply: Flipping Coins\n",
    "\n",
    "Imagine that we plan to toss a coin and want to quantify how likely we are to see heads or tails. If the coin is *fair*, the both outcomes are equally likely. Moreover if we plan nto toss the coin *n* times then the fraction of heads that we *expect* to see should exactly match the *expected* fraction of tails. \n",
    "\n",
    "One intuitive way to see this is by symmetry. For every possible outcome with n<sub>h</sub> heads and n<sub>t</sub> = (n - n<sub>h</sub> tails, there is an equally likely outcome with n<sub>t</sub> heads and n<sub>h</sub> tails. Notice that this is only possible if on average we expect 1/2 of the tosses to come up heads and 1/2 to come up tails. In practice, if you conduct this experiment many times with n = 1000000 tosses each, you might never see a trial where n<sub>h</sub> = n<sub>t</sub> exactly. \n",
    "\n",
    "More formally, the quantity 1/2 is referred to as a **probability** and here it captures the certainty with which any given toss will come up heads. Probabilities assign scores between 0 and 1 to outcomes of interest, known as **events**. Here the event of interest is heads and we denote the corresponding probability *P*(heads). A probability of 1 indicates absolute certainty and a probability of 0 indicates impossibility. The frequencies n<sub>h</sub> / n and n<sub>t</sub> / n **are not probabilities but rather statistics**. \n",
    "\n",
    "**Probabilities are theoretical quantities** that underly the data generating process. In our example, the probability 1/2 is a property of the coin itself. By contrast, **statistics are imperical quantities** that are computed as functions of the observed data. Our interests in probabilistic and statistical quantities are inextricably intertwined. Specially designed statistics are called **estimators** that produce **estimates** of model parameters such as probabilities on a given dataset. \n",
    "\n",
    "Moreover, when those estimators satisfy a property called **consistency**, our estimates will converge to the corresponding probability. These inferred probabilities, in turn, tell us about the likely statistical properties of data from the same population that we might encounter in the future. \n",
    "\n",
    "Imagine that we found a real coin for which we did not know the true *P*(heads). To determine this quantity with statistical methods, we need to:\n",
    "\n",
    "1) collect some data\n",
    "\n",
    "2) design an estimator\n",
    "\n",
    "Data aquisition here is easy since we can flip the coin many times and record all the outcomes. Formally, drawing realizations from some underlying random process is called **sampling**. As you might have guessed, one natural estimator is the ratio of the number of observed heads to the total number of tosses. \n",
    "\n",
    "Suppose that the coin was in fact fair, i.e., *P*(heads) = 0.5. To simulate tosses of a fair coin, we can invoke any random number generator. There are some easy ways to draw samples of an event with probability 0.5. For example Python's `random.random` yields number in the interval [0, 1] where the probability of lying in any sub-interval [a, b] ⊂ [0, 1] is equal to b - a. Thus we can get out 0 and 1 with probability 0.5 each by testing whether the returned float number is greater than 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee6283e-20a4-47f2-aa3d-c502e5cd805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads, tails:  [60, 40]\n"
     ]
    }
   ],
   "source": [
    "num_tosses = 100\n",
    "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
    "tails = num_tosses - heads \n",
    "print(\"heads, tails: \", [heads, tails])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ce9d4-eced-4e77-907c-d8f514d4f9c8",
   "metadata": {},
   "source": [
    "More generally, we can simulate multiple draws from any variable with a finite number of possible outcomes (like the toss of a coin or roll of a die) by calling the multinomial function, setting the first argument to the number of draws and the second as a list of probabilities associated with each of the possible outcomes. To simulate ten tosses of a fair coin, we assign probability vector [0.5, 0.5], interpreting index 0 as heads and index 1 as tails. The function returns a vector with length equal to the number of possible outcomes (here, 2), where the first component tells us the number of occurrences of heads and the second component tells us the number of occurrences of tails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82f1968-0a7a-4c67-919f-61497e7cb689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53., 47.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_probs = torch.tensor([0.5, 0.5])\n",
    "Multinomial(100, fair_probs).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465443e-dd51-4098-90d0-db195bf35d9b",
   "metadata": {},
   "source": [
    "Each time you run this sampling process, you will receive a new random value that may differ from the previous outcome. Dividing by the number of tosses gives us the **frequency** of each outcome in our data. Note that these frequencies, just like the probabilities that they are intended to estimate, sum to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2606e25-78da-4e3b-9ce8-26e665c5d3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4700, 0.5300])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multinomial(100, fair_probs).sample() / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1735f-5c8e-4c3f-921a-f7c944cf2b59",
   "metadata": {},
   "source": [
    "Here, even though our simulated coin is fair (we ourselves set the probabilities [0.5, 0.5]), the counts of heads and tails may not be identical. That is because we only drew a relatively small number of samples. If we did not implement the simulation ourselves, and only saw the outcome, how would we know if the coin were slightly unfair or if the possible deviation from 1/2 was just an artifact of the small sample size? Let's see what happens when we simulate 10,000 tosses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de78c98-e94c-4492-ad48-b54a7664ecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4952, 0.5048])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Multinomial(10000, fair_probs).sample()\n",
    "counts / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b65a62-d0bf-4761-906e-5e985bcd0cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = Multinomial(1, fair_probs).sample((10000,))\n",
    "cum_counts = counts.cumsum(dim=0)\n",
    "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
    "estimates = estimates.numpy()\n",
    "\n",
    "plt.figure(figsize=(4.5, 3.5))\n",
    "plt.plot(estimates[:, 0], label=\"P(coin=heads)\")\n",
    "plt.plot(estimates[:, 1], label=\"P(coin=heads)\")\n",
    "plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Estimated probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99328c5e-e178-46ba-8466-66cc03afda29",
   "metadata": {},
   "source": [
    "Each solid curve corresponding to one of the two values of the coin and gives our estimated probability that the coin turns up that value after each group of experiments. The dashed black line gives the true underlying probability. As we get more data by conducting more experiments, the curves converge towards the true probability. You might already begin to see the shape of some of the more advanced questions that preoccupy statisticians: How quickly does this convergence happen? If we had already tested many coins manufactured at the same plant, how might we incorporate this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda35de-ff4e-4081-8490-d9be1d2e1e17",
   "metadata": {},
   "source": [
    "## A More Formal Treatment \n",
    "\n",
    "We have already gotten pretty far: posing a probabilistic model, generating synthetic data, running a statistical estimator, empirically assessing convergence, and reporting error metrics (checking the deviation). However, to go much further, we will needs to be more precise. \n",
    "\n",
    "When dealing with randomness, we denote the set of possible outcomes S and call it the **sample space** or **outcome space**. Here, each element is a distinct possible **outcome**. In the case of flipping a single coin, S = {heads,tails}. For a single die, S = {1,2,3,4,5,6}. When flipping two coins, possible outcomes are {(heads,heads),(heads,tails),(tails,heads),(tails,tails)}. **Events** are subsets of the sample space. For instance, the event \"the first coin toss comes up heads\" corresponds to the set {(heads,heads),(heads,tails)}. Whenever the outcome *z* of a random experiment statisfies *z* ∈ A, then event A has occurred. For a single roll of a die, we could define the events \"seeing a 5\" (A = {5}) and \"seeing an odd number\" (B = {1,3,5}). In this case, if the die came up 5, we would say that both A and B occurred. On the other hand, if *z* = 3, then A did not occur but B did. \n",
    "\n",
    "A **probability function** maps events onto real values *P*: A ⊆ S --> [0,1]. The probability, denoted *P*(A), of an event A in a given sample space S, has the following properties:\n",
    "\n",
    "1) The probability of an event A is a nonnegative real number, i.e., *P*(A) ≥ 0;\n",
    "   \n",
    "2) The probability of the entire sample spaces is 1, i.e., *P*(S) = 1\n",
    "\n",
    "3) For any countable sequence of events A<sub>1</sub>,A<sub>2</sub>, . . .that are **mutually exclusive** (i.e., A<sub>i</sub> ∩ A<sub>j</sub> = 0 for all i ≠ j), the probability that any of them happens is equal to the sum of their individual probabilities, i.e., *P*(U<sup>∞</sup><sub>i=1</sub> A<sub>i</sub>) = Σ<sup>∞</sup><sub>i=1</sub> *P*(A<sub>i</sub>).\n",
    "\n",
    "\n",
    "These axioms of probability theory, proposed by Kolmogorov (1933), can be applied to rapidly derive a number of important consequences. For instance, it follows immediately that the probability of any event A *or* its complement A' occuring is 1 (because A U A' = S). We can also prove that *P*(0) = 0 because 1 = *P*(S U S') = *P*(S U 0) = *P*(S) + P(0) = 1 + *P*(0). Consequently, the probability of any event A *and* its complement A' occuring simultaneously is *P*(A ∩ A') = 0. Informally, this tells us that impossible events have zero probability of occurring. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be08b4-3ff0-4559-bc43-2e2b0beae257",
   "metadata": {},
   "source": [
    "## Random Variables\n",
    "\n",
    "When we spoke about events like the roll of a die coming up odds or the first coin toss coming up heads, we were invoking the idea of a **random variable**. Formally, random variables are mappings from an underlying sample space to a set of (possibly many) values. You might wonder how a random variable is different from the sample space, since both are collections of outcomes. Importantly, random variables can be much coarser than the raw sample space. We can define random variable like \"greater than 0.5\" even when the underlying sample space is infinite, e.g., points on the line segment between 0 and 1. \n",
    "\n",
    "Additionally, multiple random variables can share the same underlying sample space. For example “whether my home alarm goes off” and “whether my house was burgled” are both binary random variables that share an underlying sample space. Consequently, knowing the value taken by one random variable can tell us something about the likely value of another random variable. Knowing that the alarm went off, we might suspect that the house was likely burglarized. \n",
    "\n",
    "Every value taken by a random variable corresponds to a subset of the underlying sample space. Thus the occurrence where the random variable *X* takes value v, denoted by *X* = v, is an **event** and *P*(*X* = v) denotes its probability. Sometimes this notation can get clunky, and we can exploit notation when the context is clear. For example, we might use *P*(X), as a shorthand to express a statement that is true for all of the values that the random variables *X* and *Y* can take, i.e., for all *i*, *j* it holds that *P*(*X* = i and *Y* = j) = *P*(*X* = i)*P*(*Y* = j). \n",
    "\n",
    "Other times, we exploit the notation by writing *P*(v) when the random variable is clear from the context. Since an event in probability theory is a set of outcomes from the sample space, we can specify a range of values for a random variable to take. For example, *P*(1 ≤ *X* ≤ 3) denotes the probability of the event {1 ≤ *X* ≤ 3}. \n",
    "\n",
    "Notice that there is a subtle difference between **discrete** random variables, like flips of a coin or tosses of a die, and **continuous** ones, like the weight and the height of a person sampled at random from the population. In this scenario, we seldom really care about someone's exact height. What's more, if we took precise enough measurements, we would find that exceedingly few two people on the planet have the exact same height. In fact, with fine enough measurements, you would never have the same height when you wake up and when you go to sleep. There's practically no point in asking about the exact probability that someone is 1.801392782910287192 meters tall. Instead, we typically care more about being able to say whether someone's height falls into a given interval, say between 1.79 and 1.81 meters. In these cases we work with **probability densities**. The height of exactly 1.80 meters has no probability, but nonzero density. To work out the probability assigned to an interval, we must take an **integral** of the density over the that interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92581f58-af2f-48be-9a58-0a97a063faa1",
   "metadata": {},
   "source": [
    "## Multiple Random Variables\n",
    "\n",
    "Most of machine learning is concerned with relationships like *P*(*X*,*Y*) = *P*(*X*)*P*(*Y*)). Here, the sample space would be the population of  interest, say customers who transact with a business, photographs on the internet, or proteins known to biologists. Each random variable would represent the (unknown) value of a different attribute. Whenever we sample an individual from the population, we observe a realization of each of the random variables. Because the values taken by random variables correspond to subsets of the sample space that could be overlapping, partially overlapping, or entirely disjointed, knowing the value taken by one random variable can cause us to update our beliefs about which values of another random variable are likely.\n",
    "\n",
    "If a patient walks into a hospital and we observe that they are having trouble breathing and have lost their sense of smell, then we believe that they are more likely to have COVID-19 than we might if they had no trouble breathing and a perfectly ordingary sense of smell. When working with multiple random variables, we can construct events corresponding to every combination of values that the variables can jointly take. The probability function that assigns probabilities to each of these combintations (e.g., *A* = *a* and *B* = *b*) is called the **joint probability** function and simply returns the probability assigned to the intersection of the corresponding subsets of the sample space. The **joint probability** assigned to the event where random variables *A* and *B* take values *a* and *b*, respectively, is denoted *P*(*A* = *a*,*B* = *b*), where the comma indicates \"and\". \n",
    "\n",
    "Notice that for any values *a* and *b*, it follows that *P*(*A* = *a*,*B* = *b*) ≤ *P*(*A* = *a*) and *P*(*A* = *a*,*B* = *b*) ≤ *P*(*B* = *b*), since *A* = *a* and *B* = *b* to happen, *A* = *a* has to happen **and** *B* = *b* also has to happen. Interestingly enough, the joint probability tells us all that we can know about these random variables in a probabilistic sense, and can be used to derive many other useful quantities, including recovering the individual distributions *P*(*A*) and *P*(*B*). To recover *P*(*A* = a) we simply sum up *P*(*A* = *a*,*B* = *b*) over all values of *v* that the random variable *B* can take: *P*(*A* = *a*) = Σ<sub>v</sub>*P*(*A* = *a*,*B* = *b*). \n",
    "\n",
    "The ratio ((*A* = *a*,*B* = *b*) / *P*(*A*=*a*)) ≤ 1 turns out to be extremely important. It is called **the conditional probability**, and is denoted via the \"|\" symbol: *P*(*B* = *b* | *A* = *a*) = *P*(*A* = *a*,*B* = *b*)/*P*(*A* = *a*). It tells us the new probability associated with the event *B* = *b*, once we condition on the fact *A* = *a* took place. We can think of this conditional probability as restricting attention only to the subset of the sample space associated with *A* = *a* and then renormalizing so that all probabilities sum to 1. Conditional probabilities are in fact just ordinary probabilities and thus respect all of the axioms, as long as we condition all terms on the same event and thus restrict attention to the same sample space. \n",
    "\n",
    "For instance, for disjoint events B and B', we have that *P*(B u B' | *A* = *a*) = *P*(B | *A* = *a*) + *P*(B' | *A* = *a*). Using the definition of conditional probabilities, we can derive the famous result called **Bayes' theorem**. By construction, we have that *P*(A,B) = *P*(*B* | *A*)*P*(*A*) and *P*(*A*,*B*) = *P*(*A* | *B*)*P*(*B*). Combining both equations yields *P*(*B* | *A*)*P*(*A*)= *P*(*A* | *B*)*P*(*B*) and hence: *P*(*A* | *B*) = (*P*(*B* | *A*)*P*(*A*) / *P*(*B*))\n",
    "\n",
    "This simple equation has profound implications because it allowsus to reverse the order of conditioning. If we know how to estimate *P*(*B* | *A*), *P*(*A*), and *P*(*B*), then we can estimate *P*(*A* | *B*). We often find it easier to eastimate one term directly but not the other and Bayes' theorem can come to the rescue here. For example, if we know the prevalence of symptoms for a given disease, and the overall prevalences of the disease and symptoms, respectively, we can determine how likely someone is to have the disease based on their symptoms. \n",
    "\n",
    "In some cases we might not have direct access to *P*(*B*), such as the prevalence of symptoms. In this case a simplified version of Bayes' theorem comes in handy: *P*(*A* | *B*) ∝ *P*(*B* | *A*)*P*(*A*). Since we know that *P*(*A* | *B*) must be normalized to 1, i.e.   Σ<sub>a</sub>*P*(*A* = *a* | *B*) = 1, we can use it to compute *P*(*A* | *B*) = (*P*(*B* | *A*)*P*(*A*) / Σ<sub>a</sub>*P*(*B* | *A* = *a*)*P*(*A* = *a*))\n",
    "\n",
    "In Bayesian statistics, we think of an observer as possessing some *subjective* prior beliefs about the plausibility of the available hypotheses encoded in the *prior* *P*(*H*), and a **likelihood function** that says how likely one is to observe any value of the collected evidence for each of the hypotheses in the class *P*(*E* | *H*). Bayes' theorem is then interpreted as telling us how to update the initial *prior* *P*(*H*) in light of the available evidence *E* to produce **posterior** beliefs *P*(*H* | *E*) = (*P*(*E* | *H*)*P*(*H*) / *P*(*E*). Informally, this can be state as \"posterior equals prior times likelihood, divided by the evidence\". Now, because the evidence *P*(*E*) is the same for all hypotheses, we can get away with simply normalizing over the hypotheses. \n",
    "\n",
    "Notice that Σ<sub>a</sub>*P*(*A* = *a* | *B*) = 1 also allows us to **marginalize** over random variables. That is to say, we can drop variables from a joint distribution such as *P*(*A*,*B*). After all, we have that Σ<sub>a</sub>*P*(*B* | *A* = *a*)*P*(*A* = *a*) = Σ<sub>a</sub>*P*(*B*,*A* = *a*) = *P*(*B*,*A* = *a*) = *P*(*B*). \n",
    "\n",
    "**Independence** is another fundamentally important concept that forms the backbone of many important ideas in statistics. In short, two variables are independent if conditioning on the value of *A* does not cause any change to the probability distribution associated with *B* and vice versa. More formally, independence, denoted *A* ⊥ *B*, requires that *P*(*A* | *B*) = *P*(*A*) and, consequently, that *P*(*A*,*B*) = *P*(*A* | *B*)*P*(*B*) = *P*(*A*)*P*(*B*). Independence is often an appropriate assumption. For instance, if the random variable *A* represents the outcome from flipping one fair coin and the random variable *B* represents the outcome from tossing another, then knowing whether *A* came up heads should not influence the probability of *B* coming up heads. \n",
    "\n",
    "Independence is especially useful when it holds among the successive draws of our data from some underlying distribution (which allows us to make strong statistical conclusions) or when it holds among various variables in our data, allowing us to work with simpler models that encode this independence structure. On the other hand, estimating dependencies among random variables is often the very aim of learning. We care to estimate the probability of disease given symptoms specifically because we believe that diseases and symptoms are *not* independent. \n",
    "\n",
    "Notice that because conditional probabilities are proper probabilities, the concepts of independence and dependence also apply to them. Two random variables *A* and *B* are **conditionally independent** given a third variable *C* if and only if *P*(*A*,*B* | *C*) = *P*(*A* | *C*)*P*(*B* | *C*). It's quite interesting that two variables can be independent in general but become dependent when conditioning on a third. This often occurs when the two random variables *A* and *B* correspond to causes of some third variable *C*. For example, broken bones and lung cancer might be independent in the general population, however if we condition on being in the hospital, then we might find that broken bones are negatively correlated with lung cancer. That's because the broken bones **explains away* why some person is in the hospital and thus lowers the probability that they are hospitalized because of having lung cancer. Coversely, two dependent random variables can become independent upon conditioning on a third. This often happens when two otherwise unrelated events have a common cause. Shoe size and reading level are highly correlated among elementary school students, but this correlation disappears if we condition on age. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a560a4a-e0ce-40f5-b9d5-39110bdb3457",
   "metadata": {},
   "source": [
    "## A More Thorough Example\n",
    "\n",
    "Assume that a doctor administers an HIV test to a patient. Assume that this test is fairly accurate and fails only with 1% probability if the patient is healthy but reported as having the disease, or in other words, healthy patients test positive in 1% of cases. Let's also assume the test never fails to detect HIV if the patient actually has it. \n",
    "\n",
    "We can use *D*<sub>1</sub> ∈ {0,1} to indicate the diagnosis (0 if negative and 1 if positive) and *H* ∈ {0,1} to denote the HIV status. \n",
    "\n",
    "\n",
    "|Conditional Probability:| H = 1  |  H = 0|\n",
    "\n",
    "|*P*(*D*<sub>1</sub> = 1 | *H*) | 1 |   0.01|\n",
    "\n",
    "|*P*(*D*<sub>1</sub> = 0 | *H*) | 0 |   0.99|\n",
    "\n",
    "\n",
    "Notice that the column sums all 1 but the row sums do not since they are conditional probabilities. Let's now compute the probability of the patient having HIV if the test comes back positive, i.e., *P*(*H* = 1 | *D*<sub>1</sub> = 1). Intuitively this is going to depend on how common the disease is, since it affects the number of false positives. Let's assume that the population is fairly free of the disease, e.g., *P*(*H* = 1) = 0.0015. To apply Bayes' Theorem, this is where we'll need to apply marginalization to determine:\n",
    "\n",
    "*P*(*D*<sub>1</sub> = 1)=*P*(*D*<sub>1</sub> = 1, *H* = 0) + *P*(*D*<sub>1</sub> = 1,*H* = 1)\n",
    "\n",
    "=*P*(*D*<sub>1</sub> = 1 | *H* = 0)*P*(*H* = 0) + *P*(*D*<sub>1</sub> = 1, *H* = 1)*P*(*H* = 1) = 0.011485\n",
    "\n",
    "This then leads us to: \n",
    "\n",
    "*P*(*H* = 1 | *D*<sub>1</sub> = 1) = ( P*(*D*<sub>1</sub> = 1 | *H* = 1)*P*(*H* = 1) / *P*(*D*<sub>1</sub> = 1) ) = 0.1306\n",
    "\n",
    "Put another way, there is only a 13.06% chance that the patient actually has HIV, despite the test being pretty accurate. As demonstrated, probability can be counterintuitive. What should a patient do upon receiving news that they've tested positive? Most likely the patient would ask the physician to administer another test to validate the results. The second test has different characteristics and it is not as good as the first one. \n",
    "\n",
    "\n",
    "|Conditional Probability:| H = 1  |  H = 0|\n",
    "\n",
    "|*P*(*D*<sub>2</sub> = 1 | *H*) = 0.98 |   0.03|\n",
    "\n",
    "|*P*(*D*<sub>2</sub> = 0 | *H*) = 0.02 |   0.97|\n",
    "\n",
    "\n",
    "Let's say that, unfortunately, the second test for this patient comes back positive as well. Let's now calculate the requisite probabilities to invoke Bayes' Theorem by assuming conditional independence:\n",
    "\n",
    "*P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1 | *H* = 0) = *P*(*D*<sub>1</sub> = 1 | *H* = 0)*P*(*D*<sub>2</sub> = 1 | *H* = 0) = 0.0003,\n",
    "\n",
    "*P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1 | *H* = 1) = *P*(*D*<sub>1</sub> = 1 | *H* = 1)*P*(*D*<sub>2</sub> = 1 | *H* = 1) = 0.98\n",
    "\n",
    "Now we can apply marginalization to obtain the probability that both tests come back positive:\n",
    "\n",
    "*P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1) \n",
    "\n",
    "= *P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1,*H* = 0) + *P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1,*H* = 1)\n",
    "\n",
    "= *P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1 | *H* = 0)*P*(*H* = 0) + *P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1 | *H* = 1)*P*(*H* = 1)\n",
    "\n",
    "= 0.00176955\n",
    "\n",
    "Finally, the probability of our patient having HIV given that both tests were positive is: \n",
    "\n",
    "*P*(*H* = 1 | *D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1) = ( P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1 | *H* = 1)*P*(*H* = 1) / *P*(*D*<sub>1</sub> = 1,*D*<sub>2</sub> = 1) ) = 0.8307.\n",
    "\n",
    "That is to say, the second test allowed us to gain much higher confidence that not all is well. Despite the second test being considerablly less accurate than the first one, it still significantly improved our estimate. The assumption of both tests being conditionally independent of each other was *crucial* for our ability to generate a more accurate estimate. Take the extreme case where we run the same test twice.  In this scenario, we would expect the same outcome both times, hence no additional insight is gained from running the same test again. However the astute reader may notice that the diagnosis behaved like a **classifier** hiding in plain sight, where our ability to decide whether a patient is healthy increases as we obtain more features (test outcomes in this context). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788676b-077b-41e2-8ec1-54525b0a0985",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
